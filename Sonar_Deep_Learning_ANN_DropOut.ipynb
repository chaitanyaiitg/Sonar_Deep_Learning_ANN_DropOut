{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sonar_Deep_Learning_ANN_DropOut.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iig0a3Sbm2i",
        "outputId": "59abf254-8441-4af4-adf0-a78767999026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "! pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLuJ3IyBbzUk",
        "outputId": "925682b3-b8d2-41e5-ea5a-dff84a3e9c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! pip install keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBH6WN3Db5qw",
        "outputId": "375a63eb-1413-4f50-ac86-453e514d359d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "! pip install pandas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPqXRMj_b5wC",
        "outputId": "98e8222d-0b1a-4410-fd65-219f0035b023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version: 2.3.1\n",
            "Hub version: 0.9.0\n",
            "WARNING:tensorflow:From <ipython-input-4-c62ce35fd0be>:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izjchs6sb51O"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D,MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from glob import glob\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgdvwuWPb56c"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBNVQkSVb5_d",
        "outputId": "74a428e5-0c74-4dcb-8e60-df1d3c248b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBYFY4Pbb6E2"
      },
      "source": [
        "file=\"/content/drive/My Drive/Colab Notebooks/sonar.all-data.csv\"\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUPoix_vb6KO",
        "outputId": "2744aab6-e5df-433a-b526-510ca61d013c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(file)\n",
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.0200</th>\n",
              "      <th>0.0371</th>\n",
              "      <th>0.0428</th>\n",
              "      <th>0.0207</th>\n",
              "      <th>0.0954</th>\n",
              "      <th>0.0986</th>\n",
              "      <th>0.1539</th>\n",
              "      <th>0.1601</th>\n",
              "      <th>0.3109</th>\n",
              "      <th>0.2111</th>\n",
              "      <th>0.1609</th>\n",
              "      <th>0.1582</th>\n",
              "      <th>0.2238</th>\n",
              "      <th>0.0645</th>\n",
              "      <th>0.0660</th>\n",
              "      <th>0.2273</th>\n",
              "      <th>0.3100</th>\n",
              "      <th>0.2999</th>\n",
              "      <th>0.5078</th>\n",
              "      <th>0.4797</th>\n",
              "      <th>0.5783</th>\n",
              "      <th>0.5071</th>\n",
              "      <th>0.4328</th>\n",
              "      <th>0.5550</th>\n",
              "      <th>0.6711</th>\n",
              "      <th>0.6415</th>\n",
              "      <th>0.7104</th>\n",
              "      <th>0.8080</th>\n",
              "      <th>0.6791</th>\n",
              "      <th>0.3857</th>\n",
              "      <th>0.1307</th>\n",
              "      <th>0.2604</th>\n",
              "      <th>0.5121</th>\n",
              "      <th>0.7547</th>\n",
              "      <th>0.8537</th>\n",
              "      <th>0.8507</th>\n",
              "      <th>0.6692</th>\n",
              "      <th>0.6097</th>\n",
              "      <th>0.4943</th>\n",
              "      <th>0.2744</th>\n",
              "      <th>0.0510</th>\n",
              "      <th>0.2834</th>\n",
              "      <th>0.2825</th>\n",
              "      <th>0.4256</th>\n",
              "      <th>0.2641</th>\n",
              "      <th>0.1386</th>\n",
              "      <th>0.1051</th>\n",
              "      <th>0.1343</th>\n",
              "      <th>0.0383</th>\n",
              "      <th>0.0324</th>\n",
              "      <th>0.0232</th>\n",
              "      <th>0.0027</th>\n",
              "      <th>0.0065</th>\n",
              "      <th>0.0159</th>\n",
              "      <th>0.0072</th>\n",
              "      <th>0.0167</th>\n",
              "      <th>0.0180</th>\n",
              "      <th>0.0084</th>\n",
              "      <th>0.0090</th>\n",
              "      <th>0.0032</th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0286</td>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>0.0174</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1201</td>\n",
              "      <td>0.1833</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.3039</td>\n",
              "      <td>0.2988</td>\n",
              "      <td>0.4250</td>\n",
              "      <td>0.6343</td>\n",
              "      <td>0.8198</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9988</td>\n",
              "      <td>0.9508</td>\n",
              "      <td>0.9025</td>\n",
              "      <td>0.7234</td>\n",
              "      <td>0.5122</td>\n",
              "      <td>0.2074</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.5890</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.2043</td>\n",
              "      <td>0.5782</td>\n",
              "      <td>0.5389</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.3411</td>\n",
              "      <td>0.5067</td>\n",
              "      <td>0.5580</td>\n",
              "      <td>0.4778</td>\n",
              "      <td>0.3299</td>\n",
              "      <td>0.2198</td>\n",
              "      <td>0.1407</td>\n",
              "      <td>0.2856</td>\n",
              "      <td>0.3807</td>\n",
              "      <td>0.4158</td>\n",
              "      <td>0.4054</td>\n",
              "      <td>0.3296</td>\n",
              "      <td>0.2707</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.0723</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1192</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0494</td>\n",
              "      <td>0.0264</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0038</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0346</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0177</td>\n",
              "      <td>0.0393</td>\n",
              "      <td>0.1630</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.2328</td>\n",
              "      <td>0.2684</td>\n",
              "      <td>0.3108</td>\n",
              "      <td>0.2933</td>\n",
              "      <td>0.2275</td>\n",
              "      <td>0.0994</td>\n",
              "      <td>0.1801</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.2732</td>\n",
              "      <td>0.2862</td>\n",
              "      <td>0.2034</td>\n",
              "      <td>0.1740</td>\n",
              "      <td>0.4130</td>\n",
              "      <td>0.6879</td>\n",
              "      <td>0.8120</td>\n",
              "      <td>0.8453</td>\n",
              "      <td>0.8919</td>\n",
              "      <td>0.9300</td>\n",
              "      <td>0.9987</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8104</td>\n",
              "      <td>0.6199</td>\n",
              "      <td>0.6041</td>\n",
              "      <td>0.5547</td>\n",
              "      <td>0.4160</td>\n",
              "      <td>0.1472</td>\n",
              "      <td>0.0849</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0969</td>\n",
              "      <td>0.1411</td>\n",
              "      <td>0.1676</td>\n",
              "      <td>0.1200</td>\n",
              "      <td>0.1201</td>\n",
              "      <td>0.1036</td>\n",
              "      <td>0.1977</td>\n",
              "      <td>0.1339</td>\n",
              "      <td>0.0902</td>\n",
              "      <td>0.1085</td>\n",
              "      <td>0.1521</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.0858</td>\n",
              "      <td>0.0290</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0298</td>\n",
              "      <td>0.0564</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1018</td>\n",
              "      <td>0.1030</td>\n",
              "      <td>0.2154</td>\n",
              "      <td>0.3085</td>\n",
              "      <td>0.3425</td>\n",
              "      <td>0.2990</td>\n",
              "      <td>0.1402</td>\n",
              "      <td>0.1235</td>\n",
              "      <td>0.1534</td>\n",
              "      <td>0.1901</td>\n",
              "      <td>0.2429</td>\n",
              "      <td>0.2120</td>\n",
              "      <td>0.2395</td>\n",
              "      <td>0.3272</td>\n",
              "      <td>0.5949</td>\n",
              "      <td>0.8302</td>\n",
              "      <td>0.9045</td>\n",
              "      <td>0.9888</td>\n",
              "      <td>0.9912</td>\n",
              "      <td>0.9448</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9092</td>\n",
              "      <td>0.7412</td>\n",
              "      <td>0.7691</td>\n",
              "      <td>0.7117</td>\n",
              "      <td>0.5304</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0928</td>\n",
              "      <td>0.1297</td>\n",
              "      <td>0.1159</td>\n",
              "      <td>0.1226</td>\n",
              "      <td>0.1768</td>\n",
              "      <td>0.0345</td>\n",
              "      <td>0.1562</td>\n",
              "      <td>0.0824</td>\n",
              "      <td>0.1149</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0080</td>\n",
              "      <td>0.0790</td>\n",
              "      <td>0.1255</td>\n",
              "      <td>0.0647</td>\n",
              "      <td>0.0179</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.0437</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0351</td>\n",
              "      <td>0.1171</td>\n",
              "      <td>0.1257</td>\n",
              "      <td>0.1178</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.2529</td>\n",
              "      <td>0.2716</td>\n",
              "      <td>0.2374</td>\n",
              "      <td>0.1878</td>\n",
              "      <td>0.0983</td>\n",
              "      <td>0.0683</td>\n",
              "      <td>0.1503</td>\n",
              "      <td>0.1723</td>\n",
              "      <td>0.2339</td>\n",
              "      <td>0.1962</td>\n",
              "      <td>0.1395</td>\n",
              "      <td>0.3164</td>\n",
              "      <td>0.5888</td>\n",
              "      <td>0.7631</td>\n",
              "      <td>0.8473</td>\n",
              "      <td>0.9424</td>\n",
              "      <td>0.9986</td>\n",
              "      <td>0.9699</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>0.6979</td>\n",
              "      <td>0.7717</td>\n",
              "      <td>0.7305</td>\n",
              "      <td>0.5197</td>\n",
              "      <td>0.1786</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1446</td>\n",
              "      <td>0.1066</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.1929</td>\n",
              "      <td>0.0325</td>\n",
              "      <td>0.1490</td>\n",
              "      <td>0.0328</td>\n",
              "      <td>0.0537</td>\n",
              "      <td>0.1309</td>\n",
              "      <td>0.0910</td>\n",
              "      <td>0.0757</td>\n",
              "      <td>0.1059</td>\n",
              "      <td>0.1005</td>\n",
              "      <td>0.0535</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0353</td>\n",
              "      <td>0.0490</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.1354</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>0.1123</td>\n",
              "      <td>0.1945</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>0.2898</td>\n",
              "      <td>0.2812</td>\n",
              "      <td>0.1578</td>\n",
              "      <td>0.0273</td>\n",
              "      <td>0.0673</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.2070</td>\n",
              "      <td>0.2645</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.5685</td>\n",
              "      <td>0.6990</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.9242</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9979</td>\n",
              "      <td>0.8297</td>\n",
              "      <td>0.7032</td>\n",
              "      <td>0.7141</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>0.4961</td>\n",
              "      <td>0.2584</td>\n",
              "      <td>0.0969</td>\n",
              "      <td>0.0776</td>\n",
              "      <td>0.0364</td>\n",
              "      <td>0.1572</td>\n",
              "      <td>0.1823</td>\n",
              "      <td>0.1349</td>\n",
              "      <td>0.0849</td>\n",
              "      <td>0.0492</td>\n",
              "      <td>0.1367</td>\n",
              "      <td>0.1552</td>\n",
              "      <td>0.1548</td>\n",
              "      <td>0.1319</td>\n",
              "      <td>0.0985</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0489</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0126</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0272</td>\n",
              "      <td>0.0214</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.0655</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.1843</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>0.2720</td>\n",
              "      <td>0.2442</td>\n",
              "      <td>0.1665</td>\n",
              "      <td>0.0336</td>\n",
              "      <td>0.1302</td>\n",
              "      <td>0.1708</td>\n",
              "      <td>0.2177</td>\n",
              "      <td>0.3175</td>\n",
              "      <td>0.3714</td>\n",
              "      <td>0.4552</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>0.7397</td>\n",
              "      <td>0.8062</td>\n",
              "      <td>0.8837</td>\n",
              "      <td>0.9432</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.7603</td>\n",
              "      <td>0.7123</td>\n",
              "      <td>0.8358</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.4567</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.1549</td>\n",
              "      <td>0.1641</td>\n",
              "      <td>0.1869</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1713</td>\n",
              "      <td>0.0959</td>\n",
              "      <td>0.0768</td>\n",
              "      <td>0.0847</td>\n",
              "      <td>0.2076</td>\n",
              "      <td>0.2505</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.1439</td>\n",
              "      <td>0.1470</td>\n",
              "      <td>0.0991</td>\n",
              "      <td>0.0041</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0181</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0129</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>207 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032  R\n",
              "0    0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044  R\n",
              "1    0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078  R\n",
              "2    0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117  R\n",
              "3    0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094  R\n",
              "4    0.0286  0.0453  0.0277  0.0174  0.0384  ...  0.0057  0.0027  0.0051  0.0062  R\n",
              "..      ...     ...     ...     ...     ...  ...     ...     ...     ...     ... ..\n",
              "202  0.0187  0.0346  0.0168  0.0177  0.0393  ...  0.0065  0.0115  0.0193  0.0157  M\n",
              "203  0.0323  0.0101  0.0298  0.0564  0.0760  ...  0.0034  0.0032  0.0062  0.0067  M\n",
              "204  0.0522  0.0437  0.0180  0.0292  0.0351  ...  0.0140  0.0138  0.0077  0.0031  M\n",
              "205  0.0303  0.0353  0.0490  0.0608  0.0167  ...  0.0034  0.0079  0.0036  0.0048  M\n",
              "206  0.0260  0.0363  0.0136  0.0272  0.0214  ...  0.0040  0.0036  0.0061  0.0115  M\n",
              "\n",
              "[207 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVqnBFu6hN2c"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RtuEDIKrI5I",
        "outputId": "c2984424-2e05-418e-828f-09152dfdff8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(207, 61)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPUrEV8NhCJA",
        "outputId": "dc98c437-f9ff-4279-f3e4-05d96388c220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['0.0200', '0.0371', '0.0428', '0.0207', '0.0954', '0.0986', '0.1539',\n",
              "       '0.1601', '0.3109', '0.2111', '0.1609', '0.1582', '0.2238', '0.0645',\n",
              "       '0.0660', '0.2273', '0.3100', '0.2999', '0.5078', '0.4797', '0.5783',\n",
              "       '0.5071', '0.4328', '0.5550', '0.6711', '0.6415', '0.7104', '0.8080',\n",
              "       '0.6791', '0.3857', '0.1307', '0.2604', '0.5121', '0.7547', '0.8537',\n",
              "       '0.8507', '0.6692', '0.6097', '0.4943', '0.2744', '0.0510', '0.2834',\n",
              "       '0.2825', '0.4256', '0.2641', '0.1386', '0.1051', '0.1343', '0.0383',\n",
              "       '0.0324', '0.0232', '0.0027', '0.0065', '0.0159', '0.0072', '0.0167',\n",
              "       '0.0180', '0.0084', '0.0090', '0.0032', 'R'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RYxY1cRmtVx",
        "outputId": "6f6e8f44-2d1f-4655-ea8e-f5dc277415ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0200    0\n",
              "0.0371    0\n",
              "0.0428    0\n",
              "0.0207    0\n",
              "0.0954    0\n",
              "         ..\n",
              "0.0180    0\n",
              "0.0084    0\n",
              "0.0090    0\n",
              "0.0032    0\n",
              "R         0\n",
              "Length: 61, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzX2O-RUhgbV",
        "outputId": "327ae915-ff54-4867-d339-1bb5c6c0e906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0200    176\n",
              "0.0371    181\n",
              "0.0428    189\n",
              "0.0207    180\n",
              "0.0954    192\n",
              "         ... \n",
              "0.0180    120\n",
              "0.0084    124\n",
              "0.0090    118\n",
              "0.0032    109\n",
              "R           2\n",
              "Length: 61, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OMJbk2ChgrZ",
        "outputId": "9a7644b9-6c05-462c-eaf3-a5199065a1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0200    float64\n",
              "0.0371    float64\n",
              "0.0428    float64\n",
              "0.0207    float64\n",
              "0.0954    float64\n",
              "           ...   \n",
              "0.0180    float64\n",
              "0.0084    float64\n",
              "0.0090    float64\n",
              "0.0032    float64\n",
              "R          object\n",
              "Length: 61, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QI5yOMthggM",
        "outputId": "e339cc74-2455-49d2-dc0e-9130754c2150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.heatmap(df.isnull())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ffa2b313dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wBWJJsUq1sU",
        "outputId": "4fad0988-1620-4d6f-c2d2-dfd00d4c46a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "sns.countplot('R', data=df)\n",
        "plt.show()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ci_pLMNrtMi"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder=LabelEncoder()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tNhSLVKrtJT",
        "outputId": "fba0a6bb-7291-47d3-db1c-b58e181d4d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df1=df.select_dtypes(include='object')\n",
        "df1.columns"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['R'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDNDGrsfoqjI"
      },
      "source": [
        "cols=['R',]\n",
        "for i in cols:\n",
        "  df[i]=encoder.fit_transform(df[i])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB3Ery-b4UZw",
        "outputId": "bbb80be4-68b9-4a32-a271-b70fef81cd74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.0200</th>\n",
              "      <th>0.0371</th>\n",
              "      <th>0.0428</th>\n",
              "      <th>0.0207</th>\n",
              "      <th>0.0954</th>\n",
              "      <th>0.0986</th>\n",
              "      <th>0.1539</th>\n",
              "      <th>0.1601</th>\n",
              "      <th>0.3109</th>\n",
              "      <th>0.2111</th>\n",
              "      <th>0.1609</th>\n",
              "      <th>0.1582</th>\n",
              "      <th>0.2238</th>\n",
              "      <th>0.0645</th>\n",
              "      <th>0.0660</th>\n",
              "      <th>0.2273</th>\n",
              "      <th>0.3100</th>\n",
              "      <th>0.2999</th>\n",
              "      <th>0.5078</th>\n",
              "      <th>0.4797</th>\n",
              "      <th>0.5783</th>\n",
              "      <th>0.5071</th>\n",
              "      <th>0.4328</th>\n",
              "      <th>0.5550</th>\n",
              "      <th>0.6711</th>\n",
              "      <th>0.6415</th>\n",
              "      <th>0.7104</th>\n",
              "      <th>0.8080</th>\n",
              "      <th>0.6791</th>\n",
              "      <th>0.3857</th>\n",
              "      <th>0.1307</th>\n",
              "      <th>0.2604</th>\n",
              "      <th>0.5121</th>\n",
              "      <th>0.7547</th>\n",
              "      <th>0.8537</th>\n",
              "      <th>0.8507</th>\n",
              "      <th>0.6692</th>\n",
              "      <th>0.6097</th>\n",
              "      <th>0.4943</th>\n",
              "      <th>0.2744</th>\n",
              "      <th>0.0510</th>\n",
              "      <th>0.2834</th>\n",
              "      <th>0.2825</th>\n",
              "      <th>0.4256</th>\n",
              "      <th>0.2641</th>\n",
              "      <th>0.1386</th>\n",
              "      <th>0.1051</th>\n",
              "      <th>0.1343</th>\n",
              "      <th>0.0383</th>\n",
              "      <th>0.0324</th>\n",
              "      <th>0.0232</th>\n",
              "      <th>0.0027</th>\n",
              "      <th>0.0065</th>\n",
              "      <th>0.0159</th>\n",
              "      <th>0.0072</th>\n",
              "      <th>0.0167</th>\n",
              "      <th>0.0180</th>\n",
              "      <th>0.0084</th>\n",
              "      <th>0.0090</th>\n",
              "      <th>0.0032</th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0286</td>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>0.0174</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1201</td>\n",
              "      <td>0.1833</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.3039</td>\n",
              "      <td>0.2988</td>\n",
              "      <td>0.4250</td>\n",
              "      <td>0.6343</td>\n",
              "      <td>0.8198</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9988</td>\n",
              "      <td>0.9508</td>\n",
              "      <td>0.9025</td>\n",
              "      <td>0.7234</td>\n",
              "      <td>0.5122</td>\n",
              "      <td>0.2074</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.5890</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.2043</td>\n",
              "      <td>0.5782</td>\n",
              "      <td>0.5389</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.3411</td>\n",
              "      <td>0.5067</td>\n",
              "      <td>0.5580</td>\n",
              "      <td>0.4778</td>\n",
              "      <td>0.3299</td>\n",
              "      <td>0.2198</td>\n",
              "      <td>0.1407</td>\n",
              "      <td>0.2856</td>\n",
              "      <td>0.3807</td>\n",
              "      <td>0.4158</td>\n",
              "      <td>0.4054</td>\n",
              "      <td>0.3296</td>\n",
              "      <td>0.2707</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.0723</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1192</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0494</td>\n",
              "      <td>0.0264</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0038</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0346</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0177</td>\n",
              "      <td>0.0393</td>\n",
              "      <td>0.1630</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.2328</td>\n",
              "      <td>0.2684</td>\n",
              "      <td>0.3108</td>\n",
              "      <td>0.2933</td>\n",
              "      <td>0.2275</td>\n",
              "      <td>0.0994</td>\n",
              "      <td>0.1801</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.2732</td>\n",
              "      <td>0.2862</td>\n",
              "      <td>0.2034</td>\n",
              "      <td>0.1740</td>\n",
              "      <td>0.4130</td>\n",
              "      <td>0.6879</td>\n",
              "      <td>0.8120</td>\n",
              "      <td>0.8453</td>\n",
              "      <td>0.8919</td>\n",
              "      <td>0.9300</td>\n",
              "      <td>0.9987</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8104</td>\n",
              "      <td>0.6199</td>\n",
              "      <td>0.6041</td>\n",
              "      <td>0.5547</td>\n",
              "      <td>0.4160</td>\n",
              "      <td>0.1472</td>\n",
              "      <td>0.0849</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0969</td>\n",
              "      <td>0.1411</td>\n",
              "      <td>0.1676</td>\n",
              "      <td>0.1200</td>\n",
              "      <td>0.1201</td>\n",
              "      <td>0.1036</td>\n",
              "      <td>0.1977</td>\n",
              "      <td>0.1339</td>\n",
              "      <td>0.0902</td>\n",
              "      <td>0.1085</td>\n",
              "      <td>0.1521</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.0858</td>\n",
              "      <td>0.0290</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0298</td>\n",
              "      <td>0.0564</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1018</td>\n",
              "      <td>0.1030</td>\n",
              "      <td>0.2154</td>\n",
              "      <td>0.3085</td>\n",
              "      <td>0.3425</td>\n",
              "      <td>0.2990</td>\n",
              "      <td>0.1402</td>\n",
              "      <td>0.1235</td>\n",
              "      <td>0.1534</td>\n",
              "      <td>0.1901</td>\n",
              "      <td>0.2429</td>\n",
              "      <td>0.2120</td>\n",
              "      <td>0.2395</td>\n",
              "      <td>0.3272</td>\n",
              "      <td>0.5949</td>\n",
              "      <td>0.8302</td>\n",
              "      <td>0.9045</td>\n",
              "      <td>0.9888</td>\n",
              "      <td>0.9912</td>\n",
              "      <td>0.9448</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9092</td>\n",
              "      <td>0.7412</td>\n",
              "      <td>0.7691</td>\n",
              "      <td>0.7117</td>\n",
              "      <td>0.5304</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0928</td>\n",
              "      <td>0.1297</td>\n",
              "      <td>0.1159</td>\n",
              "      <td>0.1226</td>\n",
              "      <td>0.1768</td>\n",
              "      <td>0.0345</td>\n",
              "      <td>0.1562</td>\n",
              "      <td>0.0824</td>\n",
              "      <td>0.1149</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0080</td>\n",
              "      <td>0.0790</td>\n",
              "      <td>0.1255</td>\n",
              "      <td>0.0647</td>\n",
              "      <td>0.0179</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.0437</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0351</td>\n",
              "      <td>0.1171</td>\n",
              "      <td>0.1257</td>\n",
              "      <td>0.1178</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.2529</td>\n",
              "      <td>0.2716</td>\n",
              "      <td>0.2374</td>\n",
              "      <td>0.1878</td>\n",
              "      <td>0.0983</td>\n",
              "      <td>0.0683</td>\n",
              "      <td>0.1503</td>\n",
              "      <td>0.1723</td>\n",
              "      <td>0.2339</td>\n",
              "      <td>0.1962</td>\n",
              "      <td>0.1395</td>\n",
              "      <td>0.3164</td>\n",
              "      <td>0.5888</td>\n",
              "      <td>0.7631</td>\n",
              "      <td>0.8473</td>\n",
              "      <td>0.9424</td>\n",
              "      <td>0.9986</td>\n",
              "      <td>0.9699</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>0.6979</td>\n",
              "      <td>0.7717</td>\n",
              "      <td>0.7305</td>\n",
              "      <td>0.5197</td>\n",
              "      <td>0.1786</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1446</td>\n",
              "      <td>0.1066</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.1929</td>\n",
              "      <td>0.0325</td>\n",
              "      <td>0.1490</td>\n",
              "      <td>0.0328</td>\n",
              "      <td>0.0537</td>\n",
              "      <td>0.1309</td>\n",
              "      <td>0.0910</td>\n",
              "      <td>0.0757</td>\n",
              "      <td>0.1059</td>\n",
              "      <td>0.1005</td>\n",
              "      <td>0.0535</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0353</td>\n",
              "      <td>0.0490</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.1354</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>0.1123</td>\n",
              "      <td>0.1945</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>0.2898</td>\n",
              "      <td>0.2812</td>\n",
              "      <td>0.1578</td>\n",
              "      <td>0.0273</td>\n",
              "      <td>0.0673</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.2070</td>\n",
              "      <td>0.2645</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.5685</td>\n",
              "      <td>0.6990</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.9242</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9979</td>\n",
              "      <td>0.8297</td>\n",
              "      <td>0.7032</td>\n",
              "      <td>0.7141</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>0.4961</td>\n",
              "      <td>0.2584</td>\n",
              "      <td>0.0969</td>\n",
              "      <td>0.0776</td>\n",
              "      <td>0.0364</td>\n",
              "      <td>0.1572</td>\n",
              "      <td>0.1823</td>\n",
              "      <td>0.1349</td>\n",
              "      <td>0.0849</td>\n",
              "      <td>0.0492</td>\n",
              "      <td>0.1367</td>\n",
              "      <td>0.1552</td>\n",
              "      <td>0.1548</td>\n",
              "      <td>0.1319</td>\n",
              "      <td>0.0985</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0489</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0126</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0272</td>\n",
              "      <td>0.0214</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.0655</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.1843</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>0.2720</td>\n",
              "      <td>0.2442</td>\n",
              "      <td>0.1665</td>\n",
              "      <td>0.0336</td>\n",
              "      <td>0.1302</td>\n",
              "      <td>0.1708</td>\n",
              "      <td>0.2177</td>\n",
              "      <td>0.3175</td>\n",
              "      <td>0.3714</td>\n",
              "      <td>0.4552</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>0.7397</td>\n",
              "      <td>0.8062</td>\n",
              "      <td>0.8837</td>\n",
              "      <td>0.9432</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.7603</td>\n",
              "      <td>0.7123</td>\n",
              "      <td>0.8358</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.4567</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.1549</td>\n",
              "      <td>0.1641</td>\n",
              "      <td>0.1869</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1713</td>\n",
              "      <td>0.0959</td>\n",
              "      <td>0.0768</td>\n",
              "      <td>0.0847</td>\n",
              "      <td>0.2076</td>\n",
              "      <td>0.2505</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.1439</td>\n",
              "      <td>0.1470</td>\n",
              "      <td>0.0991</td>\n",
              "      <td>0.0041</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0181</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0129</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>207 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032  R\n",
              "0    0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044  1\n",
              "1    0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078  1\n",
              "2    0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117  1\n",
              "3    0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094  1\n",
              "4    0.0286  0.0453  0.0277  0.0174  0.0384  ...  0.0057  0.0027  0.0051  0.0062  1\n",
              "..      ...     ...     ...     ...     ...  ...     ...     ...     ...     ... ..\n",
              "202  0.0187  0.0346  0.0168  0.0177  0.0393  ...  0.0065  0.0115  0.0193  0.0157  0\n",
              "203  0.0323  0.0101  0.0298  0.0564  0.0760  ...  0.0034  0.0032  0.0062  0.0067  0\n",
              "204  0.0522  0.0437  0.0180  0.0292  0.0351  ...  0.0140  0.0138  0.0077  0.0031  0\n",
              "205  0.0303  0.0353  0.0490  0.0608  0.0167  ...  0.0034  0.0079  0.0036  0.0048  0\n",
              "206  0.0260  0.0363  0.0136  0.0272  0.0214  ...  0.0040  0.0036  0.0061  0.0115  0\n",
              "\n",
              "[207 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCM1iVxI4U3E",
        "outputId": "7c27602e-344f-4caf-b6de-a48c5544ecd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0200    float64\n",
              "0.0371    float64\n",
              "0.0428    float64\n",
              "0.0207    float64\n",
              "0.0954    float64\n",
              "           ...   \n",
              "0.0180    float64\n",
              "0.0084    float64\n",
              "0.0090    float64\n",
              "0.0032    float64\n",
              "R           int64\n",
              "Length: 61, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l3O1D2I5xSb"
      },
      "source": [
        "X = df.drop('R',axis=1)\n",
        "y = df['R']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=1)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jftbg2kV5xOt",
        "outputId": "2fcdc2aa-843f-4c43-b679-e6a268d846cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(155, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrYVvTAd9FUY",
        "outputId": "e45ba957-f2d8-4672-acc6-8767fbb4bb54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV9vnRf15xLu",
        "outputId": "a0ccc5ba-44fa-4290-8e90-7a9a6d53dd53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_train.columns)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLUq_l9u5xHC"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "s = StandardScaler()\n",
        "X_train = s.fit_transform(X_train)\n",
        "X_test = s.transform(X_test)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur5_241-5xBu",
        "outputId": "5ca8c503-a33a-4d64-ccf9-f5b44640499a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(60, input_dim=60, activation='relu'),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "r=model.fit(X_train, y_train, epochs=100, batch_size=8,validation_data=(X_test,y_test))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6594 - accuracy: 0.5419 - val_loss: 0.6747 - val_accuracy: 0.5577\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7355 - val_loss: 0.6288 - val_accuracy: 0.6731\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8065 - val_loss: 0.5744 - val_accuracy: 0.7308\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8258 - val_loss: 0.5388 - val_accuracy: 0.7885\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8710 - val_loss: 0.5076 - val_accuracy: 0.7308\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2496 - accuracy: 0.9161 - val_loss: 0.4721 - val_accuracy: 0.7692\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2063 - accuracy: 0.9419 - val_loss: 0.4459 - val_accuracy: 0.7692\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1679 - accuracy: 0.9548 - val_loss: 0.4518 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1388 - accuracy: 0.9613 - val_loss: 0.4588 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.9742 - val_loss: 0.4778 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0959 - accuracy: 0.9871 - val_loss: 0.4645 - val_accuracy: 0.7885\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9871 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9806 - val_loss: 0.4747 - val_accuracy: 0.7692\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9871 - val_loss: 0.5150 - val_accuracy: 0.7308\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9935 - val_loss: 0.5034 - val_accuracy: 0.7692\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9935 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.7308\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.7692\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.5208 - val_accuracy: 0.7692\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.7692\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.8077\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.7885\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 0.7885\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.7885\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.7885\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.7885\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.7885\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 0.7885\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.7885\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.7885\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5843 - val_accuracy: 0.7885\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5860 - val_accuracy: 0.7885\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.7885\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.7885\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.7885\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.7885\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.7885\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.7885\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 0.7885\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6240 - val_accuracy: 0.7885\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.7885\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.7885\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 0.7885\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.7885\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 0.7885\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.7885\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6438 - val_accuracy: 0.7885\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 9.7809e-04 - accuracy: 1.0000 - val_loss: 0.6454 - val_accuracy: 0.7885\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 9.0902e-04 - accuracy: 1.0000 - val_loss: 0.6470 - val_accuracy: 0.7885\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 8.5438e-04 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.7885\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 8.0841e-04 - accuracy: 1.0000 - val_loss: 0.6537 - val_accuracy: 0.7885\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 7.6022e-04 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.7885\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 7.1839e-04 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.7885\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 6.8269e-04 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.7885\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 6.4539e-04 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.7885\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 6.1508e-04 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.7885\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.8317e-04 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.7885\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 5.5921e-04 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.7885\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 5.3234e-04 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.7885\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 5.0658e-04 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.7885\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 4.8443e-04 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.7885\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 4.6488e-04 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.7885\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 4.4566e-04 - accuracy: 1.0000 - val_loss: 0.6876 - val_accuracy: 0.7885\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 4.2699e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.7885\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 4.0911e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.7885\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 3.9522e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.7885\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 3.7968e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.7885\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 3.6403e-04 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.7885\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 3.5197e-04 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.7885\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 3.3836e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.7885\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 3.2722e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.7885\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 3.1482e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.7885\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 3.0448e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.7885\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.9442e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.7885\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.8377e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.7885\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2.7492e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.7885\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.6432e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.7885\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.5700e-04 - accuracy: 1.0000 - val_loss: 0.7176 - val_accuracy: 0.7885\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.4662e-04 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.7885\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.3846e-04 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.7885\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.2985e-04 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.7885\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.2314e-04 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.7885\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.1506e-04 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.7885\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.0890e-04 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.7885\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2.0273e-04 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.7885\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.9610e-04 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.7885\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.8942e-04 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.7885\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.8438e-04 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.7885\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.7858e-04 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.7885\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.7385e-04 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.7885\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.6820e-04 - accuracy: 1.0000 - val_loss: 0.7420 - val_accuracy: 0.7885\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.6277e-04 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.7885\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.5858e-04 - accuracy: 1.0000 - val_loss: 0.7429 - val_accuracy: 0.7885\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.5459e-04 - accuracy: 1.0000 - val_loss: 0.7454 - val_accuracy: 0.7885\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.4956e-04 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.7885\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.4548e-04 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.7885\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.4114e-04 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 0.7885\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.3753e-04 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.7885\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.3380e-04 - accuracy: 1.0000 - val_loss: 0.7538 - val_accuracy: 0.7885\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.3070e-04 - accuracy: 1.0000 - val_loss: 0.7558 - val_accuracy: 0.7885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErVPY-0_EzaP",
        "outputId": "bd08f7ad-2394-421f-d29b-c39bcea968e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "k=r.history['val_accuracy']\n",
        "print('The Validation Accuracy of ANN Model: ', np.mean(k))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Validation Accuracy of ANN Model:  0.7796154069900513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GxfnYqC4TQp",
        "outputId": "ac826e4c-c87b-4e0c-8b54-3e08d32e5295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "yp= model.predict(X_test)\n",
        "yp"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.2396256e-05],\n",
              "       [1.1917414e-06],\n",
              "       [1.2431721e-01],\n",
              "       [1.1735175e-05],\n",
              "       [9.9999642e-01],\n",
              "       [3.7734766e-02],\n",
              "       [9.7431380e-01],\n",
              "       [7.1329013e-03],\n",
              "       [1.6942182e-05],\n",
              "       [9.9999964e-01],\n",
              "       [9.9999976e-01],\n",
              "       [7.4547166e-01],\n",
              "       [3.9155159e-07],\n",
              "       [3.0209408e-03],\n",
              "       [8.4628797e-01],\n",
              "       [2.1607457e-01],\n",
              "       [9.9996710e-01],\n",
              "       [3.2571679e-06],\n",
              "       [9.9996269e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.3117836e-05],\n",
              "       [9.9050295e-01],\n",
              "       [9.9762362e-01],\n",
              "       [5.6166137e-03],\n",
              "       [1.8999893e-02],\n",
              "       [5.0709298e-04],\n",
              "       [9.9999762e-01],\n",
              "       [9.9158692e-01],\n",
              "       [9.9997091e-01],\n",
              "       [8.5760356e-04],\n",
              "       [7.8161967e-01],\n",
              "       [3.4307643e-10],\n",
              "       [9.8818946e-01],\n",
              "       [7.0875430e-01],\n",
              "       [1.0000000e+00],\n",
              "       [9.4706547e-01],\n",
              "       [9.9999988e-01],\n",
              "       [2.7846473e-03],\n",
              "       [1.0000000e+00],\n",
              "       [6.2896025e-01],\n",
              "       [9.1880793e-03],\n",
              "       [1.1560844e-05],\n",
              "       [1.0000000e+00],\n",
              "       [9.9900228e-01],\n",
              "       [1.0409104e-01],\n",
              "       [3.9639076e-06],\n",
              "       [4.5046186e-01],\n",
              "       [1.0000000e+00],\n",
              "       [3.4434775e-05],\n",
              "       [1.9725822e-02],\n",
              "       [9.5005345e-01],\n",
              "       [1.0372815e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIFO38fVBvmV"
      },
      "source": [
        "y_pred = []\n",
        "for element in yp:\n",
        "    if element > 0.5:\n",
        "        y_pred.append(1)\n",
        "    else:\n",
        "        y_pred.append(0)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1-nOn5bCEqB",
        "outputId": "435f8330-fc56-4248-d17c-2d819a40d469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSwv0VrPCGCN",
        "outputId": "2edb6aad-b695-4910-cad2-23fa85b33622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_labels=np.unique(y_pred, return_counts=True)\n",
        "y_pred_labels"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([26, 26]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNRup1qNCmUu",
        "outputId": "7f1de41a-c58f-4c7c-b93c-e572be5f5028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test_labels=np.unique(y_test, return_counts=True)\n",
        "y_test_labels"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([27, 25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A4HGX9qDGQl",
        "outputId": "97f007a8-2763-4a95-a432-933212191432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c_m = confusion_matrix(y_test, y_pred)\n",
        "c_m"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[21,  6],\n",
              "       [ 5, 20]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8EPA0H7FLmH",
        "outputId": "3b35375e-4f0f-4ee7-c201-6ee2bc31a2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize = (6,6))\n",
        "sns.heatmap(c_m,cmap= \"Reds\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' )"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ffa1718f4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nClwjpGkFVuJ",
        "outputId": "89633d0b-8d2d-465c-8eca-f714385dc0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,roc_curve,auc,accuracy_score\n",
        "acc_score = accuracy_score(y_test, y_pred)\n",
        "acc_score"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7884615384615384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKyq9pLlF6nU",
        "outputId": "98bd9c91-d848-40d6-eb4d-44dcc4801068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "X_test[0]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0200    0.0453\n",
              "0.0371    0.0523\n",
              "0.0428    0.0843\n",
              "0.0207    0.0689\n",
              "0.0954    0.1183\n",
              "           ...  \n",
              "0.0180    0.0140\n",
              "0.0084    0.0049\n",
              "0.0090    0.0052\n",
              "0.0032    0.0044\n",
              "R         1.0000\n",
              "Name: 0, Length: 61, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZTMaWSqo4Ja",
        "outputId": "f8955051-deee-48fd-d0cf-c458214e862d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186    0\n",
              "155    0\n",
              "165    0\n",
              "200    0\n",
              "58     1\n",
              "34     1\n",
              "151    0\n",
              "18     1\n",
              "202    0\n",
              "62     1\n",
              "4      1\n",
              "47     1\n",
              "110    0\n",
              "205    0\n",
              "105    0\n",
              "172    0\n",
              "31     1\n",
              "198    0\n",
              "33     1\n",
              "40     1\n",
              "175    0\n",
              "59     1\n",
              "29     1\n",
              "11     1\n",
              "124    0\n",
              "147    0\n",
              "35     1\n",
              "44     1\n",
              "51     1\n",
              "171    0\n",
              "153    0\n",
              "183    0\n",
              "28     1\n",
              "16     1\n",
              "94     1\n",
              "78     1\n",
              "38     1\n",
              "27     1\n",
              "69     1\n",
              "119    0\n",
              "206    0\n",
              "191    0\n",
              "73     1\n",
              "166    0\n",
              "138    0\n",
              "199    0\n",
              "84     1\n",
              "90     1\n",
              "123    0\n",
              "169    0\n",
              "107    0\n",
              "201    0\n",
              "Name: R, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxqM9Sh80ZYz",
        "outputId": "7544360c-126a-4f0b-9df2-d2616498caa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.iloc[0]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jia8T2dFF0kF",
        "outputId": "4f7bd287-8176-40b7-8125-d5c6ae001361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b=model.predict([[ 0.22659173, -0.33134402, -0.90270496,  0.05929915, -0.0040236 ,\n",
        "       -0.65377934, -0.4483738 ,  0.12720498,  0.30164042,  0.31273456,\n",
        "        0.41339104,  0.2829758 , -0.08513533,  0.07226079, -0.25874729,\n",
        "       -0.58511607, -0.82456764, -0.95714472, -0.82194139, -0.86294313,\n",
        "       -0.93892818, -1.04772013, -0.82699068, -0.74520161, -0.74466733,\n",
        "       -0.20847893,  0.58757087,  1.10404523,  1.49340132,  1.16427283,\n",
        "        0.13678826,  0.07919875,  0.3913261 , -0.11145355, -0.81705092,\n",
        "       -0.89715341, -0.68284265, -0.79799296, -1.15792629, -0.56436628,\n",
        "        0.38107681,  0.87596186,  0.97605593, -0.13478673, -0.06463676,\n",
        "        0.31266874,  0.57212182,  0.78144813,  1.12327414,  0.04083205,\n",
        "       -0.13351216, -0.34637659, -1.20282045, -1.27198915, -0.55340396,\n",
        "        0.15085776, -1.18554769,  0.01045561,  0.38995517, -0.27532979]])\n",
        "b"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.239626e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GibpAXdeKWOI",
        "outputId": "16db4db6-1961-4845-c3ea-7fbb78569c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if(b>0.5):\n",
        "  print('R')\n",
        "else:\n",
        "  print('M')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc3ikt_1M032",
        "outputId": "e6766e40-9c11-4c69-bdf0-a4b3119d3d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.78      0.79        27\n",
            "           1       0.77      0.80      0.78        25\n",
            "\n",
            "    accuracy                           0.79        52\n",
            "   macro avg       0.79      0.79      0.79        52\n",
            "weighted avg       0.79      0.79      0.79        52\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo5-m4-FM1yB"
      },
      "source": [
        ""
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8tSH_1RpOZg",
        "outputId": "aa7606d8-4a48-4c55-cbea-6b9acfe8fe18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "modeld = Sequential([\n",
        "    Dense(60, input_dim=60, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modeld.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "r1=modeld.fit(X_train, y_train, epochs=100, batch_size=8,validation_data=(X_test,y_test))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.8112 - accuracy: 0.4968 - val_loss: 0.6761 - val_accuracy: 0.5192\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8440 - accuracy: 0.4774 - val_loss: 0.6639 - val_accuracy: 0.5385\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7586 - accuracy: 0.5484 - val_loss: 0.6523 - val_accuracy: 0.6346\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7346 - accuracy: 0.4903 - val_loss: 0.6462 - val_accuracy: 0.6923\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6981 - accuracy: 0.5484 - val_loss: 0.6470 - val_accuracy: 0.6923\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7830 - accuracy: 0.4839 - val_loss: 0.6466 - val_accuracy: 0.7115\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6758 - accuracy: 0.5677 - val_loss: 0.6423 - val_accuracy: 0.7115\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.5871 - val_loss: 0.6379 - val_accuracy: 0.6923\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.6258 - val_loss: 0.6282 - val_accuracy: 0.7308\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5995 - accuracy: 0.6645 - val_loss: 0.6170 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.7032 - val_loss: 0.6018 - val_accuracy: 0.7692\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6137 - accuracy: 0.6645 - val_loss: 0.5872 - val_accuracy: 0.8269\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5692 - accuracy: 0.6645 - val_loss: 0.5748 - val_accuracy: 0.8077\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5776 - accuracy: 0.6516 - val_loss: 0.5590 - val_accuracy: 0.8269\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5665 - accuracy: 0.6903 - val_loss: 0.5516 - val_accuracy: 0.7885\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6452 - val_loss: 0.5415 - val_accuracy: 0.7885\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6007 - accuracy: 0.6645 - val_loss: 0.5399 - val_accuracy: 0.8269\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5254 - accuracy: 0.7226 - val_loss: 0.5289 - val_accuracy: 0.7885\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5368 - accuracy: 0.7097 - val_loss: 0.5138 - val_accuracy: 0.7692\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7097 - val_loss: 0.4924 - val_accuracy: 0.8269\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7290 - val_loss: 0.4669 - val_accuracy: 0.8269\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.8000 - val_loss: 0.4513 - val_accuracy: 0.8077\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7484 - val_loss: 0.4341 - val_accuracy: 0.8462\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7871 - val_loss: 0.4193 - val_accuracy: 0.8846\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7548 - val_loss: 0.4086 - val_accuracy: 0.8846\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7806 - val_loss: 0.4040 - val_accuracy: 0.8654\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7806 - val_loss: 0.3945 - val_accuracy: 0.8654\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7935 - val_loss: 0.3882 - val_accuracy: 0.8846\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5012 - accuracy: 0.7677 - val_loss: 0.3860 - val_accuracy: 0.8654\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7935 - val_loss: 0.3903 - val_accuracy: 0.8269\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7871 - val_loss: 0.3954 - val_accuracy: 0.8269\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8065 - val_loss: 0.3823 - val_accuracy: 0.8269\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7935 - val_loss: 0.3786 - val_accuracy: 0.8269\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8258 - val_loss: 0.3843 - val_accuracy: 0.8269\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8194 - val_loss: 0.3721 - val_accuracy: 0.8269\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3581 - accuracy: 0.8452 - val_loss: 0.3542 - val_accuracy: 0.8269\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3552 - accuracy: 0.8452 - val_loss: 0.3429 - val_accuracy: 0.8462\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8774 - val_loss: 0.3383 - val_accuracy: 0.8077\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8387 - val_loss: 0.3376 - val_accuracy: 0.8654\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8645 - val_loss: 0.3370 - val_accuracy: 0.8462\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8387 - val_loss: 0.3484 - val_accuracy: 0.8462\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2528 - accuracy: 0.9226 - val_loss: 0.3403 - val_accuracy: 0.8462\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2890 - accuracy: 0.8710 - val_loss: 0.3195 - val_accuracy: 0.8462\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3065 - accuracy: 0.8839 - val_loss: 0.3143 - val_accuracy: 0.8462\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.8903 - val_loss: 0.3244 - val_accuracy: 0.8077\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2579 - accuracy: 0.9226 - val_loss: 0.3313 - val_accuracy: 0.8462\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2696 - accuracy: 0.8774 - val_loss: 0.3423 - val_accuracy: 0.8462\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2822 - accuracy: 0.8839 - val_loss: 0.3451 - val_accuracy: 0.8269\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2105 - accuracy: 0.9161 - val_loss: 0.3673 - val_accuracy: 0.8269\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2632 - accuracy: 0.8710 - val_loss: 0.3628 - val_accuracy: 0.8269\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2412 - accuracy: 0.8774 - val_loss: 0.3590 - val_accuracy: 0.8462\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2602 - accuracy: 0.8968 - val_loss: 0.3638 - val_accuracy: 0.8269\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2675 - accuracy: 0.8839 - val_loss: 0.3782 - val_accuracy: 0.8462\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1795 - accuracy: 0.9355 - val_loss: 0.3905 - val_accuracy: 0.8462\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1830 - accuracy: 0.9226 - val_loss: 0.4091 - val_accuracy: 0.8462\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1865 - accuracy: 0.9097 - val_loss: 0.4428 - val_accuracy: 0.8462\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9548 - val_loss: 0.4609 - val_accuracy: 0.8462\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9355 - val_loss: 0.4195 - val_accuracy: 0.8462\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1419 - accuracy: 0.9290 - val_loss: 0.4097 - val_accuracy: 0.8462\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1339 - accuracy: 0.9742 - val_loss: 0.4304 - val_accuracy: 0.8462\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2036 - accuracy: 0.9032 - val_loss: 0.4171 - val_accuracy: 0.8654\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9355 - val_loss: 0.4213 - val_accuracy: 0.8462\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1779 - accuracy: 0.9290 - val_loss: 0.4409 - val_accuracy: 0.8462\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1560 - accuracy: 0.9419 - val_loss: 0.4393 - val_accuracy: 0.8462\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1663 - accuracy: 0.9290 - val_loss: 0.4564 - val_accuracy: 0.8269\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9484 - val_loss: 0.4694 - val_accuracy: 0.8269\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1275 - accuracy: 0.9290 - val_loss: 0.4882 - val_accuracy: 0.8269\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9742 - val_loss: 0.5049 - val_accuracy: 0.8462\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.9742 - val_loss: 0.5358 - val_accuracy: 0.8462\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2303 - accuracy: 0.9419 - val_loss: 0.4951 - val_accuracy: 0.8269\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1545 - accuracy: 0.9419 - val_loss: 0.4914 - val_accuracy: 0.8269\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9613 - val_loss: 0.4736 - val_accuracy: 0.8462\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2421 - accuracy: 0.9032 - val_loss: 0.4621 - val_accuracy: 0.8462\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9677 - val_loss: 0.4750 - val_accuracy: 0.8462\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1505 - accuracy: 0.9226 - val_loss: 0.4871 - val_accuracy: 0.8462\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1302 - accuracy: 0.9290 - val_loss: 0.4998 - val_accuracy: 0.8462\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9484 - val_loss: 0.4925 - val_accuracy: 0.8654\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9613 - val_loss: 0.5058 - val_accuracy: 0.8654\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9484 - val_loss: 0.5289 - val_accuracy: 0.8654\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.9677 - val_loss: 0.5445 - val_accuracy: 0.8654\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9613 - val_loss: 0.5265 - val_accuracy: 0.8654\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9677 - val_loss: 0.5515 - val_accuracy: 0.8654\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9226 - val_loss: 0.6357 - val_accuracy: 0.8269\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 0.9226 - val_loss: 0.6301 - val_accuracy: 0.8269\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9484 - val_loss: 0.6308 - val_accuracy: 0.8077\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9548 - val_loss: 0.6152 - val_accuracy: 0.8269\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9742 - val_loss: 0.6170 - val_accuracy: 0.8269\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9742 - val_loss: 0.6162 - val_accuracy: 0.8462\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9742 - val_loss: 0.6092 - val_accuracy: 0.8654\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9742 - val_loss: 0.6477 - val_accuracy: 0.8654\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9742 - val_loss: 0.6494 - val_accuracy: 0.8654\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9871 - val_loss: 0.6569 - val_accuracy: 0.8654\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9613 - val_loss: 0.6814 - val_accuracy: 0.8654\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9484 - val_loss: 0.7812 - val_accuracy: 0.8269\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.9548 - val_loss: 0.8201 - val_accuracy: 0.8269\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9548 - val_loss: 0.7963 - val_accuracy: 0.8462\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1249 - accuracy: 0.9548 - val_loss: 0.7826 - val_accuracy: 0.8462\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0443 - accuracy: 0.9871 - val_loss: 0.7926 - val_accuracy: 0.8462\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9742 - val_loss: 0.8317 - val_accuracy: 0.8462\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9677 - val_loss: 0.8431 - val_accuracy: 0.8462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L32qM9YZO5kc"
      },
      "source": [
        "y_pred1 = modeld.predict(X_test)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gvl7VcgPoMp",
        "outputId": "398d978b-f9af-4071-bc2a-982d4f4e42ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "k1=r1.history['val_accuracy']\n",
        "print('The Validation Accuracy of ANN Model: ', np.mean(k1))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Validation Accuracy of ANN Model:  0.8221153897047043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNKt2B43QR6h"
      },
      "source": [
        "y_pred11 = []\n",
        "for element in y_pred1:\n",
        "    if element > 0.5:\n",
        "        y_pred11.append(1)\n",
        "    else:\n",
        "        y_pred11.append(0)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmh6hEksQXSs",
        "outputId": "244b00d4-0dee-4c8f-d3b6-a0393daaf8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "y_pred11"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SfJtkSeQYjQ",
        "outputId": "a7eabbcf-6ed9-4107-d120-f6296f9efc70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_labels1=np.unique(y_pred11, return_counts=True)\n",
        "y_pred_labels1"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([29, 23]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYsWzv6PQjyw",
        "outputId": "98ca9509-f508-49fb-9e79-2e2106dcfe5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test_labels=np.unique(y_test, return_counts=True)\n",
        "y_test_labels"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([27, 25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9t4qmYxQr7Y",
        "outputId": "f1396221-f471-4aa6-c8a0-aa74e0e07edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c_m1 = confusion_matrix(y_test, y_pred11)\n",
        "c_m1"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24,  3],\n",
              "       [ 5, 20]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xisJwQzQQ0vc",
        "outputId": "24abb000-55bc-466b-8c14-e00a448ee46f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize = (6,6))\n",
        "sns.heatmap(c_m1,cmap= \"Reds\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' )"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ffa127f09e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGQGXg0CRB3Q",
        "outputId": "2dccb3dc-00a1-4100-c658-80a8bdf68c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "\n",
        "print(classification_report(y_test,y_pred11))\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86        27\n",
            "           1       0.87      0.80      0.83        25\n",
            "\n",
            "    accuracy                           0.85        52\n",
            "   macro avg       0.85      0.84      0.85        52\n",
            "weighted avg       0.85      0.85      0.85        52\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iUULDKiRpqK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2KoF4RnRJgY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}